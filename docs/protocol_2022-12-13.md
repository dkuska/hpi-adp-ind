# Protokoll 13.12.2022

## partial SPIDER PR Updates

- Wollte Besprechung heute abwarten
- run_as_compared methode reverten

## Next Steps

    - Mehrere Datensaetze
    - PartialSPIDER PR abschliessen
        - MissingValues Value anhand der Daten setzen
        - Fehlermass berechnen gegen MissingValues
        - Fuer Baseline MissingValues of 0 setzen
        - Moeglicherweise fuer Baseline BINDER benutzen statt SPIDER
  
    - Umstellung auf DataFrames
    - Budget:
        - Unterschiedliche Datentypen haben unterschiedliche Groessen im Arbeitsspeicher
        - Anzahl Tuple ist nur erste Naeherung fuer 
        - Moeglichkeit Hashing fuer Feste Groesse:
          - 
    - Input:
        - Statistiken integrieren (Smallest/Largest, Shortest/Longest, etc.)
        - Idealerweise mehrere Runs ausfuehren und Ergebnisse zusammenfuehren
        - Bloss mit Uniques arbeiten
        - 
    - Output:
        - Metadaten speichern ueber Spalten um Plausibilisierung zu machen (Wertebereich, Anzahl Eintraege, Anzahl Uniques, Werteverteilungen)
        - 
        - Zusammenfuehren der Ergebnisse mehrerer Runs


    - FNs Reduzieren:
      - MissingValues hochsetzen
      - Mehrere Runs durchfuehren und Ergebnisse zusammenfuehren
        - Schauen wie oft bestimmte INDs erkannt werden
      - 
    
    - FPs Reduzieren:
      - Plausibilisierung des Outputs mit Metadaten
      - Mehrere Runs durchfuehren und Ergebnisse zusammenfuehren
        - Vergleich der MissingValues mit Metadaten ueber die Spalten
    
    - Evaluation/Plotting:

## Fragen fuer Besprechung am Donnerstag:

- Welche Spalten-Statistiken koennen wir annehmen, dass wir haben?
    - Min/Max, Mean, Count, #Count Distinct?

- Budget:
  - Wie Implementieren? Anzahl Tuple oder Arbeitsspeicher
  - Datentypen haben unterschiedliche Groesse,
  - Anzahl Tuple ist nur Approximation
  - Budget ist dann variabler Parameter, der in Precision/Recall & Kosten Abwaegung einfliesst
  - Hash Ansatz zum Normalisieren der Groesse von Eintraegen? 
  - Ist das sinnvoll?