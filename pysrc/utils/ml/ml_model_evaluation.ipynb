{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MaxAbsScaler, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score, accuracy_score, f1_score, auc, roc_auc_score, precision_score, balanced_accuracy_score, fbeta_score, make_scorer\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/nano/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2184: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn(\"y_pred contains classes not in y_true\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 45\u001b[0m\n\u001b[1;32m     39\u001b[0m dataset_scores[\u001b[39m'\u001b[39m\u001b[39mRandomForest\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m scoring(tree_model, features, labels)\n\u001b[1;32m     40\u001b[0m model_scores\u001b[39m.\u001b[39mappend([dataset, \u001b[39m'\u001b[39m\u001b[39mRandomForest\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     41\u001b[0m                     dataset_scores[\u001b[39m'\u001b[39m\u001b[39mRandomForest\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m'\u001b[39m], dataset_scores[\u001b[39m'\u001b[39m\u001b[39mRandomForest\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[1;32m     42\u001b[0m                     dataset_scores[\u001b[39m'\u001b[39m\u001b[39mRandomForest\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m], dataset_scores[\u001b[39m'\u001b[39m\u001b[39mRandomForest\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mbalanced_accuracy\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[1;32m     43\u001b[0m                     dataset_scores[\u001b[39m'\u001b[39m\u001b[39mRandomForest\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[0;32m---> 45\u001b[0m dataset_scores[\u001b[39m'\u001b[39m\u001b[39mSVC\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m scoring(tree_model, features, labels)\n\u001b[1;32m     46\u001b[0m model_scores\u001b[39m.\u001b[39mappend([dataset, \u001b[39m'\u001b[39m\u001b[39mSVC\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m     47\u001b[0m                     dataset_scores[\u001b[39m'\u001b[39m\u001b[39mSVC\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m'\u001b[39m], dataset_scores[\u001b[39m'\u001b[39m\u001b[39mSVC\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[1;32m     48\u001b[0m                     dataset_scores[\u001b[39m'\u001b[39m\u001b[39mSVC\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m'\u001b[39m], dataset_scores[\u001b[39m'\u001b[39m\u001b[39mSVC\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mbalanced_accuracy\u001b[39m\u001b[39m'\u001b[39m], \n\u001b[1;32m     49\u001b[0m                     dataset_scores[\u001b[39m'\u001b[39m\u001b[39mSVC\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m]])\n\u001b[1;32m     51\u001b[0m dataset_scores[\u001b[39m'\u001b[39m\u001b[39mLogisticRegression\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m scoring(tree_model, features, labels) \n",
      "Cell \u001b[0;32mIn [3], line 3\u001b[0m, in \u001b[0;36mscoring\u001b[0;34m(clf, X, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscoring\u001b[39m(clf, X, y):\n\u001b[1;32m      2\u001b[0m     scores \u001b[39m=\u001b[39m {}\n\u001b[0;32m----> 3\u001b[0m     y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[1;32m      4\u001b[0m     scores[\u001b[39m'\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m recall_score(y, y_pred)\n\u001b[1;32m      5\u001b[0m     scores[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m accuracy_score(y, y_pred)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:426\u001b[0m, in \u001b[0;36mBaseDecisionTree.predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[39m\"\"\"Predict class or regression value for X.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[1;32m    405\u001b[0m \u001b[39mFor a classification model, the predicted class for each sample in X is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39m    The predicted classes, or the predict values.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    425\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 426\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X, check_input)\n\u001b[1;32m    427\u001b[0m proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree_\u001b[39m.\u001b[39mpredict(X)\n\u001b[1;32m    428\u001b[0m n_samples \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:392\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39m\"\"\"Validate the training data on predict (probabilities).\"\"\"\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[0;32m--> 392\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    393\u001b[0m     \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (\n\u001b[1;32m    394\u001b[0m         X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc\n\u001b[1;32m    395\u001b[0m     ):\n\u001b[1;32m    396\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    534\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 535\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    536\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    537\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:877\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    875\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    876\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 877\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    878\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    879\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    880\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    881\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py:2069\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[0;32m-> 2069\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def scoring(clf, X, y):\n",
    "    scores = {}\n",
    "    y_pred = clf.predict(X)\n",
    "    scores['recall'] = recall_score(y, y_pred)\n",
    "    scores['accuracy'] = accuracy_score(y, y_pred)\n",
    "    scores['f1'] = f1_score(y, y_pred)\n",
    "    scores['precision'] = precision_score(y, y_pred)\n",
    "    scores['balanced_accuracy'] = balanced_accuracy_score(y, y_pred)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "sub_folders = [f for f in os.listdir('.') if os.path.isdir(f) and 'no_' in f]\n",
    "\n",
    "model_scores = []\n",
    "for dataset in ['CATH', 'COMA', 'ENSEMBL', 'SCOP', 'TCPH', 'TESMA']:\n",
    "    dataset_scores = {}\n",
    "    \n",
    "    data_file = f'data_{dataset}.json'\n",
    "    model_folder = f'no_{dataset}'\n",
    "    \n",
    "    with open(f'./{model_folder}/forest_model.pkl', 'rb') as model_file:\n",
    "        forest_model = pickle.load(model_file)\n",
    "    with open(f'./{model_folder}/logreg_model.pkl', 'rb') as model_file:\n",
    "        logreg_model = pickle.load(model_file)\n",
    "    with open(f'./{model_folder}/svc_model.pkl', 'rb') as model_file:\n",
    "        svc_model = pickle.load(model_file)\n",
    "    with open(f'./{model_folder}/tree_model.pkl', 'rb') as model_file:\n",
    "        tree_model = pickle.load(model_file)\n",
    "    \n",
    "    features = pd.read_csv(f'./features_{dataset}.csv', index_col=0)\n",
    "    labels = pd.read_csv(f'./labels_{dataset}.csv', index_col=0).to_numpy().ravel()\n",
    "    \n",
    "    dataset_scores['DecisionTree'] = scoring(tree_model, features, labels)\n",
    "    model_scores.append([dataset, 'DecisionTree', \n",
    "                        dataset_scores['DecisionTree']['recall'], dataset_scores['DecisionTree']['accuracy'], \n",
    "                        dataset_scores['DecisionTree']['precision'], dataset_scores['DecisionTree']['balanced_accuracy'], \n",
    "                        dataset_scores['DecisionTree']['f1']])\n",
    "    \n",
    "    dataset_scores['RandomForest'] = scoring(tree_model, features, labels)\n",
    "    model_scores.append([dataset, 'RandomForest', \n",
    "                        dataset_scores['RandomForest']['recall'], dataset_scores['RandomForest']['accuracy'], \n",
    "                        dataset_scores['RandomForest']['precision'], dataset_scores['RandomForest']['balanced_accuracy'], \n",
    "                        dataset_scores['RandomForest']['f1']])\n",
    "    \n",
    "    dataset_scores['SVC'] = scoring(tree_model, features, labels)\n",
    "    model_scores.append([dataset, 'SVC', \n",
    "                        dataset_scores['SVC']['recall'], dataset_scores['SVC']['accuracy'], \n",
    "                        dataset_scores['SVC']['precision'], dataset_scores['SVC']['balanced_accuracy'], \n",
    "                        dataset_scores['SVC']['f1']])\n",
    "    \n",
    "    dataset_scores['LogisticRegression'] = scoring(tree_model, features, labels) \n",
    "    model_scores.append([dataset, 'LogisticRegression', \n",
    "                        dataset_scores['LogisticRegression']['recall'], dataset_scores['LogisticRegression']['accuracy'], \n",
    "                        dataset_scores['LogisticRegression']['precision'], dataset_scores['LogisticRegression']['balanced_accuracy'], \n",
    "                        dataset_scores['LogisticRegression']['f1']])   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(model_scores, columns=['DataSet', 'ModelType', 'Recall', 'Accuracy', 'Precision', 'BalancedAccuracy', 'F1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataSet</th>\n",
       "      <th>ModelType</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>BalancedAccuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CATH</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579274</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CATH</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579274</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CATH</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579274</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CATH</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579274</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579274</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COMA</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>COMA</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COMA</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>COMA</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ENSEMBL</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>0.562598</td>\n",
       "      <td>0.078313</td>\n",
       "      <td>0.518538</td>\n",
       "      <td>0.134133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ENSEMBL</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>0.562598</td>\n",
       "      <td>0.078313</td>\n",
       "      <td>0.518538</td>\n",
       "      <td>0.134133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ENSEMBL</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>0.562598</td>\n",
       "      <td>0.078313</td>\n",
       "      <td>0.518538</td>\n",
       "      <td>0.134133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ENSEMBL</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.467000</td>\n",
       "      <td>0.562598</td>\n",
       "      <td>0.078313</td>\n",
       "      <td>0.518538</td>\n",
       "      <td>0.134133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SCOP</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.120853</td>\n",
       "      <td>0.817969</td>\n",
       "      <td>0.078161</td>\n",
       "      <td>0.499305</td>\n",
       "      <td>0.094928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SCOP</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.120853</td>\n",
       "      <td>0.817969</td>\n",
       "      <td>0.078161</td>\n",
       "      <td>0.499305</td>\n",
       "      <td>0.094928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SCOP</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.120853</td>\n",
       "      <td>0.817969</td>\n",
       "      <td>0.078161</td>\n",
       "      <td>0.499305</td>\n",
       "      <td>0.094928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SCOP</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.120853</td>\n",
       "      <td>0.817969</td>\n",
       "      <td>0.078161</td>\n",
       "      <td>0.499305</td>\n",
       "      <td>0.094928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TCPH</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.289645</td>\n",
       "      <td>0.660384</td>\n",
       "      <td>0.195448</td>\n",
       "      <td>0.515291</td>\n",
       "      <td>0.233401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TCPH</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.289645</td>\n",
       "      <td>0.660384</td>\n",
       "      <td>0.195448</td>\n",
       "      <td>0.515291</td>\n",
       "      <td>0.233401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TCPH</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.289645</td>\n",
       "      <td>0.660384</td>\n",
       "      <td>0.195448</td>\n",
       "      <td>0.515291</td>\n",
       "      <td>0.233401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TCPH</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.289645</td>\n",
       "      <td>0.660384</td>\n",
       "      <td>0.195448</td>\n",
       "      <td>0.515291</td>\n",
       "      <td>0.233401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>TESMA</td>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>TESMA</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>TESMA</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>TESMA</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935606</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    DataSet           ModelType    Recall  Accuracy  Precision  \\\n",
       "0      CATH        DecisionTree  0.000000  0.579274   0.000000   \n",
       "1      CATH        RandomForest  0.000000  0.579274   0.000000   \n",
       "2      CATH                 SVC  0.000000  0.579274   0.000000   \n",
       "3      CATH  LogisticRegression  0.000000  0.579274   0.000000   \n",
       "4      COMA        DecisionTree  0.000000  0.250000   0.000000   \n",
       "5      COMA        RandomForest  0.000000  0.250000   0.000000   \n",
       "6      COMA                 SVC  0.000000  0.250000   0.000000   \n",
       "7      COMA  LogisticRegression  0.000000  0.250000   0.000000   \n",
       "8   ENSEMBL        DecisionTree  0.467000  0.562598   0.078313   \n",
       "9   ENSEMBL        RandomForest  0.467000  0.562598   0.078313   \n",
       "10  ENSEMBL                 SVC  0.467000  0.562598   0.078313   \n",
       "11  ENSEMBL  LogisticRegression  0.467000  0.562598   0.078313   \n",
       "12     SCOP        DecisionTree  0.120853  0.817969   0.078161   \n",
       "13     SCOP        RandomForest  0.120853  0.817969   0.078161   \n",
       "14     SCOP                 SVC  0.120853  0.817969   0.078161   \n",
       "15     SCOP  LogisticRegression  0.120853  0.817969   0.078161   \n",
       "16     TCPH        DecisionTree  0.289645  0.660384   0.195448   \n",
       "17     TCPH        RandomForest  0.289645  0.660384   0.195448   \n",
       "18     TCPH                 SVC  0.289645  0.660384   0.195448   \n",
       "19     TCPH  LogisticRegression  0.289645  0.660384   0.195448   \n",
       "20    TESMA        DecisionTree  0.000000  0.935606   0.000000   \n",
       "21    TESMA        RandomForest  0.000000  0.935606   0.000000   \n",
       "22    TESMA                 SVC  0.000000  0.935606   0.000000   \n",
       "23    TESMA  LogisticRegression  0.000000  0.935606   0.000000   \n",
       "\n",
       "    BalancedAccuracy        F1  \n",
       "0           0.579274  0.000000  \n",
       "1           0.579274  0.000000  \n",
       "2           0.579274  0.000000  \n",
       "3           0.579274  0.000000  \n",
       "4           0.250000  0.000000  \n",
       "5           0.250000  0.000000  \n",
       "6           0.250000  0.000000  \n",
       "7           0.250000  0.000000  \n",
       "8           0.518538  0.134133  \n",
       "9           0.518538  0.134133  \n",
       "10          0.518538  0.134133  \n",
       "11          0.518538  0.134133  \n",
       "12          0.499305  0.094928  \n",
       "13          0.499305  0.094928  \n",
       "14          0.499305  0.094928  \n",
       "15          0.499305  0.094928  \n",
       "16          0.515291  0.233401  \n",
       "17          0.515291  0.233401  \n",
       "18          0.515291  0.233401  \n",
       "19          0.515291  0.233401  \n",
       "20          0.935606  0.000000  \n",
       "21          0.935606  0.000000  \n",
       "22          0.935606  0.000000  \n",
       "23          0.935606  0.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilistic_scoring(clf, X, y, threshold=0.5):\n",
    "    y_pred = clf.predict_proba(X)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    \n",
    "    for predicted, actual in zip(y_pred, y):\n",
    "        if predicted[1] >= threshold and actual == 1:\n",
    "            tp += 1\n",
    "        elif predicted[1] < threshold and actual == 1:\n",
    "            fn += 1\n",
    "        elif predicted[1] >= threshold and actual == 0:\n",
    "            fp += 1\n",
    "        elif predicted[1] < threshold and actual == 0:\n",
    "            tn += 1\n",
    "        else:\n",
    "            print('WTF')\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp)  != 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0.0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) != 0 else 0.0\n",
    "    f1 = (2 * tp) / (2 * tp + fp + fn) if (2 * tp + fp + fn) != 0 else 0.0\n",
    "    \n",
    "    scores = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1\n",
    "    }\n",
    "    return scores\n",
    "\n",
    "\n",
    "sub_folders = [f for f in os.listdir('.') if os.path.isdir(f) and 'no_' in f]\n",
    "\n",
    "model_scores = []\n",
    "# for threshold in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "for threshold in [0.5]:\n",
    "    for dataset in ['CATH', 'COMA', 'ENSEMBL', 'SCOP', 'TCPH']:\n",
    "        dataset_scores = {}\n",
    "        \n",
    "        data_file = f'data_{dataset}.json'\n",
    "        model_folder = f'no_{dataset}'\n",
    "        \n",
    "        with open(f'./{model_folder}/forest_model.pkl', 'rb') as model_file:\n",
    "            forest_model = pickle.load(model_file)\n",
    "        with open(f'./{model_folder}/logreg_model.pkl', 'rb') as model_file:\n",
    "            logreg_model = pickle.load(model_file)\n",
    "        with open(f'./{model_folder}/svc_model.pkl', 'rb') as model_file:\n",
    "            svc_model = pickle.load(model_file)\n",
    "        with open(f'./{model_folder}/tree_model.pkl', 'rb') as model_file:\n",
    "            tree_model = pickle.load(model_file)\n",
    "        \n",
    "        features = pd.read_csv(f'./features_{dataset}.csv', index_col=0)\n",
    "        labels = pd.read_csv(f'./labels_{dataset}.csv', index_col=0).to_numpy().ravel()\n",
    "        \n",
    "        dataset_scores['DecisionTree'] = probabilistic_scoring(tree_model, features, labels, threshold=threshold)\n",
    "        model_scores.append([dataset, 'DecisionTree', threshold,\n",
    "                            dataset_scores['DecisionTree']['recall'], dataset_scores['DecisionTree']['accuracy'], \n",
    "                            dataset_scores['DecisionTree']['precision'], dataset_scores['DecisionTree']['f1']])\n",
    "        \n",
    "        dataset_scores['RandomForest'] = probabilistic_scoring(forest_model, features, labels, threshold=threshold)\n",
    "        model_scores.append([dataset, 'RandomForest', threshold,\n",
    "                            dataset_scores['RandomForest']['recall'], dataset_scores['RandomForest']['accuracy'], \n",
    "                            dataset_scores['RandomForest']['precision'], dataset_scores['RandomForest']['f1']])\n",
    "        \n",
    "        dataset_scores['SVC'] = probabilistic_scoring(svc_model, features, labels, threshold=threshold)\n",
    "        model_scores.append([dataset, 'SVC', threshold,\n",
    "                            dataset_scores['SVC']['recall'], dataset_scores['SVC']['accuracy'], \n",
    "                            dataset_scores['SVC']['precision'], dataset_scores['SVC']['f1']])\n",
    "        \n",
    "        dataset_scores['LogisticRegression'] = probabilistic_scoring(logreg_model, features, labels, threshold=threshold) \n",
    "        model_scores.append([dataset, 'LogisticRegression', threshold,\n",
    "                            dataset_scores['LogisticRegression']['recall'], dataset_scores['LogisticRegression']['accuracy'], \n",
    "                            dataset_scores['LogisticRegression']['precision'], dataset_scores['LogisticRegression']['f1']])   \n",
    "    \n",
    "prob_scores_df = pd.DataFrame(model_scores, columns=['DataSet', 'ModelType', 'Threshold', 'Recall', 'Accuracy', 'Precision', 'F1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_scores_df.to_csv('prob_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilistic_scoring(clf, X, y, threshold=0.5):\n",
    "    y_pred = clf.predict_proba(X)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    \n",
    "    for predicted, actual in zip(y_pred, y):\n",
    "        if predicted[1] >= threshold and actual == 1:\n",
    "            tp += 1\n",
    "        elif predicted[1] < threshold and actual == 1:\n",
    "            fn += 1\n",
    "        elif predicted[1] >= threshold and actual == 0:\n",
    "            fp += 1\n",
    "        elif predicted[1] < threshold and actual == 0:\n",
    "            tn += 1\n",
    "        else:\n",
    "            print('WTF')\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp)  != 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) != 0 else 0.0\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) != 0 else 0.0\n",
    "    f1 = (2 * tp) / (2 * tp + fp + fn) if (2 * tp + fp + fn) != 0 else 0.0\n",
    "    \n",
    "    scores = {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'accuracy': accuracy,\n",
    "        'f1': f1\n",
    "    }\n",
    "    return scores\n",
    "\n",
    "\n",
    "sub_folders = [f for f in os.listdir('.') if os.path.isdir(f) and 'no_' in f]\n",
    "\n",
    "model_scores = []\n",
    "for threshold in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "    for dataset in ['CATH', 'CENSUS', 'ENSEMBL', 'SCOP', 'TCPH']:\n",
    "        dataset_scores = {}\n",
    "        \n",
    "        data_file = f'data_{dataset}.json'\n",
    "        model_folder = f'no_{dataset}'\n",
    "        \n",
    "        features = pd.read_csv(f'./features_{dataset}.csv', index_col=0)\n",
    "        labels = pd.read_csv(f'./labels_{dataset}.csv', index_col=0).to_numpy().ravel()\n",
    "        \n",
    "        with open(f'./{model_folder}/tree_model_exclusioncriteria.pkl', 'rb') as model_file:\n",
    "            tree_model = pickle.load(model_file)\n",
    "        dataset_scores['DecisionTree'] = probabilistic_scoring(tree_model, features, labels, threshold=threshold)\n",
    "        model_scores.append([dataset, 'DecisionTree', threshold,\n",
    "                            dataset_scores['DecisionTree']['recall'], dataset_scores['DecisionTree']['accuracy'], \n",
    "                            dataset_scores['DecisionTree']['precision'], dataset_scores['DecisionTree']['f1']])\n",
    "\n",
    "        # with open(f'./{model_folder}/forest_model_smallestvalues.pkl', 'rb') as model_file:\n",
    "        #     forest_model = pickle.load(model_file)        \n",
    "        # dataset_scores['RandomForest'] = probabilistic_scoring(tree_model, features, labels, threshold=threshold)\n",
    "        # model_scores.append([dataset, 'RandomForest', threshold,\n",
    "        #                     dataset_scores['RandomForest']['recall'], dataset_scores['RandomForest']['accuracy'], \n",
    "        #                     dataset_scores['RandomForest']['precision'], dataset_scores['RandomForest']['f1']])\n",
    "\n",
    "        # with open(f'./{model_folder}/forest_model_smallestvalues.pkl', 'rb') as model_file:\n",
    "        #     forest_model = pickle.load(model_file)        \n",
    "        # dataset_scores['SVC'] = probabilistic_scoring(tree_model, features, labels, threshold=threshold)\n",
    "        # model_scores.append([dataset, 'SVC', threshold,\n",
    "        #                     dataset_scores['SVC']['recall'], dataset_scores['SVC']['accuracy'], \n",
    "        #                     dataset_scores['SVC']['precision'], dataset_scores['SVC']['f1']])\n",
    "        \n",
    "        with open(f'./{model_folder}/logreg_model_exclusioncriteria.pkl', 'rb') as model_file:\n",
    "            logreg_model = pickle.load(model_file)  \n",
    "        dataset_scores['LogisticRegression'] = probabilistic_scoring(logreg_model, features, labels, threshold=threshold) \n",
    "        model_scores.append([dataset, 'LogisticRegression', threshold,\n",
    "                            dataset_scores['LogisticRegression']['recall'], dataset_scores['LogisticRegression']['accuracy'], \n",
    "                            dataset_scores['LogisticRegression']['precision'], dataset_scores['LogisticRegression']['f1']])   \n",
    "    \n",
    "prob_scores_df = pd.DataFrame(model_scores, columns=['DataSet', 'ModelType', 'Threshold', 'Recall', 'Accuracy', 'Precision', 'F1'])\n",
    "prob_scores_df.to_csv('prob_scores_exclusioncriteria.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
